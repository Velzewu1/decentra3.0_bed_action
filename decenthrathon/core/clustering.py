#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
"""

import numpy as np
import pandas as pd
import hdbscan
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import logging
from typing import Dict, Tuple, Any
import time

logger = logging.getLogger(__name__)

def evaluate_clustering_balance(labels: np.ndarray) -> Dict[str, float]:
    """–û—Ü–µ–Ω–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
    unique_labels, counts = np.unique(labels, return_counts=True)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —à—É–º (–º–µ—Ç–∫–∞ -1 –≤ HDBSCAN)
    noise_mask = unique_labels == -1
    if noise_mask.any():
        noise_count = counts[noise_mask][0]
        valid_counts = counts[~noise_mask]
        valid_labels = unique_labels[~noise_mask]
        noise_ratio = noise_count / len(labels)
    else:
        noise_count = 0
        valid_counts = counts
        valid_labels = unique_labels
        noise_ratio = 0.0
    
    if len(valid_counts) == 0:
        return {
            'balance_ratio': 0.0,
            'largest_cluster_pct': 100.0,
            'n_clusters': 0,
            'cluster_sizes': [],
            'noise_ratio': noise_ratio
        }
    
    max_size = valid_counts.max()
    min_size = valid_counts.min()
    balance_ratio = min_size / max_size if max_size > 0 else 0
    largest_cluster_pct = max_size / len(labels) * 100
    
    return {
        'balance_ratio': balance_ratio,
        'largest_cluster_pct': largest_cluster_pct,
        'n_clusters': len(valid_labels),
        'cluster_sizes': valid_counts.tolist(),
        'noise_ratio': noise_ratio
    }

def find_optimal_n_components_auto(X: np.ndarray, params: Dict) -> int:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ 
    —á–µ—Ä–µ–∑ BIC/AIC –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    """
    logger.info("üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ BIC/AIC...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –ø–æ–∏—Å–∫–∞
    min_components = params.get('gmm_auto_min_components', 2)
    max_components = params.get('gmm_auto_max_components', min(10, X.shape[0] // 50))  # –ù–µ –±–æ–ª—å—à–µ samples/50
    
    logger.info(f"   –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ç {min_components} –¥–æ {max_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã BIC/AIC –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    results = []
    
    for n_components in range(min_components, max_components + 1):
        for covariance_type in params.get('gmm_covariance_type', ['diag', 'full'])[:2]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            try:
                gmm = GaussianMixture(
                    n_components=n_components,
                    covariance_type=covariance_type,
                    init_params=params.get('gmm_init_params', 'kmeans'),
                    max_iter=params.get('gmm_max_iter', 100),
                    tol=params.get('gmm_tol', 1e-3),
                    random_state=params.get('gmm_random_state', 42)
                )
                
                gmm.fit(X)
                
                # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
                bic = gmm.bic(X)
                aic = gmm.aic(X)
                log_likelihood = gmm.score(X) * X.shape[0]  # Total log-likelihood
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                labels = gmm.predict(X)
                balance_metrics = evaluate_clustering_balance(labels)
                silhouette = calculate_silhouette_safe(X, labels)
                
                result = {
                    'n_components': n_components,
                    'covariance_type': covariance_type,
                    'bic': bic,
                    'aic': aic,
                    'log_likelihood': log_likelihood,
                    'balance_ratio': balance_metrics['balance_ratio'],
                    'silhouette': silhouette,
                    'gmm': gmm,
                    'labels': labels
                }
                
                results.append(result)
                
                silhouette_str = f"{silhouette:.3f}" if silhouette is not None else "N/A"
                logger.info(f"     n={n_components}, cov={covariance_type}: BIC={bic:.1f}, AIC={aic:.1f}, "
                          f"–±–∞–ª–∞–Ω—Å={balance_metrics['balance_ratio']:.3f}, silhouette={silhouette_str}")
                
            except Exception as e:
                logger.error(f"   –û—à–∏–±–∫–∞ –¥–ª—è n_components={n_components}, cov={covariance_type}: {e}")
    
    if not results:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        return 3
    
    # –í—ã–±–∏—Ä–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π
    criterion = params.get('gmm_auto_criterion', 'bic').lower()
    
    if criterion == 'bic':
        # –ú–µ–Ω—å—à–∏–π BIC = –ª—É—á—à–µ
        best_result = min(results, key=lambda x: x['bic'])
        logger.info(f"‚úÖ BIC –≤—ã–±—Ä–∞–ª: {best_result['n_components']} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (BIC={best_result['bic']:.1f})")
    elif criterion == 'aic':
        # –ú–µ–Ω—å—à–∏–π AIC = –ª—É—á—à–µ  
        best_result = min(results, key=lambda x: x['aic'])
        logger.info(f"‚úÖ AIC –≤—ã–±—Ä–∞–ª: {best_result['n_components']} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (AIC={best_result['aic']:.1f})")
    elif criterion == 'combined':
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π: BIC + –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        for result in results:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º BIC –∫ [0,1] –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            min_bic = min(r['bic'] for r in results)
            max_bic = max(r['bic'] for r in results)
            normalized_bic = (result['bic'] - min_bic) / (max_bic - min_bic) if max_bic != min_bic else 0
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 50% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π + 30% –±–∞–ª–∞–Ω—Å + 20% silhouette
            combined_score = (
                (1 - normalized_bic) * 0.5 +  # –ß–µ–º –º–µ–Ω—å—à–µ BIC, —Ç–µ–º –ª—É—á—à–µ
                result['balance_ratio'] * 0.3 +
                (result['silhouette'] if result['silhouette'] is not None else 0) * 0.2
            )
            result['combined_score'] = combined_score
        
        best_result = max(results, key=lambda x: x.get('combined_score', 0))
        logger.info(f"‚úÖ Combined –∫—Ä–∏—Ç–µ—Ä–∏–π –≤—ã–±—Ä–∞–ª: {best_result['n_components']} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ "
                   f"(score={best_result.get('combined_score', 0):.3f})")
    else:
        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π {criterion}, –∏—Å–ø–æ–ª—å–∑—É–µ–º BIC")
        best_result = min(results, key=lambda x: x['bic'])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    setattr(find_optimal_n_components_auto, '_last_results', results)
    
    return best_result['n_components']

def run_gmm_clustering_auto(X: np.ndarray, params: Dict) -> Dict[str, Any]:
    """
    GMM –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    """
    logger.info("üîÆ –ó–∞–ø—É—Å–∫ GMM –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    optimal_n_components = find_optimal_n_components_auto(X, params)
    
    logger.info(f"üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {optimal_n_components}")
    
    # –¢–µ–ø–µ—Ä—å —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    best_result = None
    best_score = -1
    results = []
    
    for covariance_type in params.get('gmm_covariance_type', ['full', 'tied', 'diag', 'spherical']):
        try:
            start_time = time.time()
            
            gmm = GaussianMixture(
                n_components=optimal_n_components,
                covariance_type=covariance_type,
                init_params=params.get('gmm_init_params', 'kmeans'),
                max_iter=params.get('gmm_max_iter', 100),
                tol=params.get('gmm_tol', 1e-3),
                random_state=params.get('gmm_random_state', 42)
            )
            
            labels = gmm.fit_predict(X)
            fit_time = time.time() - start_time
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            balance_metrics = evaluate_clustering_balance(labels)
            silhouette = calculate_silhouette_safe(X, labels)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
            bic = gmm.bic(X)
            aic = gmm.aic(X)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: –±–∞–ª–∞–Ω—Å (50%) + silhouette (30%) + BIC bonus (20%)
            bic_bonus = 1.0 / (1.0 + abs(bic) / 1000.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º BIC
            if silhouette is not None:
                combined_score = (balance_metrics['balance_ratio'] * 0.5 + 
                                silhouette * 0.3 + 
                                bic_bonus * 0.2)
            else:
                combined_score = balance_metrics['balance_ratio'] * 0.5 + bic_bonus * 0.2
            
            result = {
                'labels': labels,
                'clusterer': gmm,
                'params': {
                    'algorithm': 'gmm_auto',
                    'n_components': optimal_n_components,
                    'covariance_type': covariance_type
                },
                'metrics': {
                    **balance_metrics,
                    'silhouette': silhouette,
                    'combined_score': combined_score,
                    'fit_time': fit_time,
                    'bic': bic,
                    'aic': aic,
                    'optimal_n_components': optimal_n_components
                }
            }
            
            results.append(result)
            
            silhouette_str = f"{silhouette:.3f}" if silhouette is not None else "N/A"
            logger.info(f"  n_components={optimal_n_components}, cov={covariance_type}: "
                      f"{balance_metrics['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
                      f"–±–∞–ª–∞–Ω—Å={balance_metrics['balance_ratio']:.3f}, "
                      f"–º–∞–∫—Å={balance_metrics['largest_cluster_pct']:.1f}%, "
                      f"silhouette={silhouette_str}, BIC={bic:.1f}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if combined_score > best_score:
                best_score = combined_score
                best_result = result
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ GMM (n={optimal_n_components}, cov={covariance_type}): {e}")
    
    if best_result is None:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å GMM –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
    
    logger.info(f"‚úÖ –õ—É—á—à–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π GMM —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "
              f"{best_result['metrics']['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
              f"–±–∞–ª–∞–Ω—Å={best_result['metrics']['balance_ratio']:.3f}, "
              f"BIC={best_result['metrics']['bic']:.1f}, "
              f"score={best_score:.3f}")
    
    return {'gmm_auto_best': best_result, 'gmm_auto_all_results': results}

def calculate_silhouette_safe(X: np.ndarray, labels: np.ndarray) -> float:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç silhouette score"""
    try:
        # –£–±–∏—Ä–∞–µ–º —à—É–º –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        non_noise = labels != -1
        if np.sum(non_noise) < 2:
            return None
            
        unique_labels = np.unique(labels[non_noise])
        if len(unique_labels) < 2:
            return None
            
        return silhouette_score(X[non_noise], labels[non_noise])
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ silhouette score: {e}")
        return None

def run_gmm_clustering(X: np.ndarray, params: Dict) -> Dict[str, Any]:
    """Gaussian Mixture Model –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"""
    logger.info("üîÆ –ó–∞–ø—É—Å–∫ GMM –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    best_result = None
    best_score = -1
    results = []
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    for n_components in params.get('gmm_n_components_range', [3, 4, 5]):
        for covariance_type in params.get('gmm_covariance_type', ['full']):
            try:
                start_time = time.time()
                
                gmm = GaussianMixture(
                    n_components=n_components,
                    covariance_type=covariance_type,
                    init_params=params.get('gmm_init_params', 'kmeans'),
                    max_iter=params.get('gmm_max_iter', 100),
                    tol=params.get('gmm_tol', 1e-3),
                    random_state=params.get('gmm_random_state', 42)
                )
                
                labels = gmm.fit_predict(X)
                fit_time = time.time() - start_time
                
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                balance_metrics = evaluate_clustering_balance(labels)
                silhouette = calculate_silhouette_safe(X, labels)
                
                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: –±–∞–ª–∞–Ω—Å (60%) + silhouette (40%)
                if silhouette is not None:
                    combined_score = balance_metrics['balance_ratio'] * 0.6 + silhouette * 0.4
                else:
                    combined_score = balance_metrics['balance_ratio'] * 0.6
                
                result = {
                    'labels': labels,
                    'clusterer': gmm,
                    'params': {
                        'algorithm': 'gmm',
                        'n_components': n_components,
                        'covariance_type': covariance_type
                    },
                    'metrics': {
                        **balance_metrics,
                        'silhouette': silhouette,
                        'combined_score': combined_score,
                        'fit_time': fit_time
                    }
                }
                
                results.append(result)
                
                silhouette_str = f"{silhouette:.3f}" if silhouette is not None else "N/A"
                logger.info(f"  n_components={n_components}, cov={covariance_type}: "
                          f"{balance_metrics['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
                          f"–±–∞–ª–∞–Ω—Å={balance_metrics['balance_ratio']:.3f}, "
                          f"–º–∞–∫—Å={balance_metrics['largest_cluster_pct']:.1f}%, "
                          f"silhouette={silhouette_str}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if combined_score > best_score:
                    best_score = combined_score
                    best_result = result
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ GMM (n={n_components}, cov={covariance_type}): {e}")
    
    if best_result is None:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å GMM –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
    
    logger.info(f"‚úÖ –õ—É—á—à–∏–π GMM —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "
              f"{best_result['metrics']['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
              f"–±–∞–ª–∞–Ω—Å={best_result['metrics']['balance_ratio']:.3f}, "
              f"score={best_score:.3f}")
    
    return {'gmm_best': best_result, 'gmm_all_results': results}

def run_kmeans_clustering(X: np.ndarray, params: Dict) -> Dict[str, Any]:
    """K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"""
    logger.info("üìä –ó–∞–ø—É—Å–∫ K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    best_result = None
    best_score = -1
    results = []
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    for n_clusters in params.get('kmeans_n_clusters_range', [3, 4, 5, 6, 7]):
        try:
            start_time = time.time()
            
            kmeans = KMeans(
                n_clusters=n_clusters,
                init=params.get('kmeans_init', 'k-means++'),
                n_init=params.get('kmeans_n_init', 10),
                max_iter=params.get('kmeans_max_iter', 300),
                random_state=params.get('kmeans_random_state', 42)
            )
            
            labels = kmeans.fit_predict(X)
            fit_time = time.time() - start_time
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            balance_metrics = evaluate_clustering_balance(labels)
            silhouette = calculate_silhouette_safe(X, labels)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score
            if silhouette is not None:
                combined_score = balance_metrics['balance_ratio'] * 0.6 + silhouette * 0.4
            else:
                combined_score = balance_metrics['balance_ratio'] * 0.6
            
            result = {
                'labels': labels,
                'clusterer': kmeans,
                'params': {
                    'algorithm': 'kmeans',
                    'n_clusters': n_clusters
                },
                'metrics': {
                    **balance_metrics,
                    'silhouette': silhouette,
                    'combined_score': combined_score,
                    'fit_time': fit_time
                }
            }
            
            results.append(result)
            
            silhouette_str = f"{silhouette:.3f}" if silhouette is not None else "N/A"
            logger.info(f"  k={n_clusters}: "
                      f"{balance_metrics['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
                      f"–±–∞–ª–∞–Ω—Å={balance_metrics['balance_ratio']:.3f}, "
                      f"–º–∞–∫—Å={balance_metrics['largest_cluster_pct']:.1f}%, "
                      f"silhouette={silhouette_str}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if combined_score > best_score:
                best_score = combined_score
                best_result = result
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ K-Means (k={n_clusters}): {e}")
    
    if best_result is None:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
    
    logger.info(f"‚úÖ –õ—É—á—à–∏–π K-Means —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "
              f"{best_result['metrics']['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
              f"–±–∞–ª–∞–Ω—Å={best_result['metrics']['balance_ratio']:.3f}")
    
    return {'kmeans_best': best_result, 'kmeans_all_results': results}

def run_hdbscan_clustering(X: np.ndarray, params: Dict) -> Dict[str, Any]:
    """HDBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è)"""
    logger.info("üî¨ –ó–∞–ø—É—Å–∫ HDBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    best_result = None
    best_score = -1
    results = []
    
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    min_cluster_sizes = params.get('min_cluster_size_range', [5, 10])[:2]
    min_samples_list = params.get('min_samples_range', [3, 5])[:2]
    
    for min_cluster_size in min_cluster_sizes:
        for min_samples in min_samples_list:
            try:
                start_time = time.time()
                
                clusterer = hdbscan.HDBSCAN(
                    min_cluster_size=min_cluster_size,
                    min_samples=min_samples,
                    cluster_selection_epsilon=0.0,
                    cluster_selection_method='eom',
                    metric='euclidean',
                    n_jobs=params.get('n_jobs', -1),
                    core_dist_n_jobs=params.get('core_dist_n_jobs', -1)
                )
                
                labels = clusterer.fit_predict(X)
                fit_time = time.time() - start_time
                
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                balance_metrics = evaluate_clustering_balance(labels)
                silhouette = calculate_silhouette_safe(X, labels)
                
                # –î–ª—è HDBSCAN –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç silhouette
                if silhouette is not None:
                    combined_score = silhouette * 0.7 + balance_metrics['balance_ratio'] * 0.3
                else:
                    combined_score = balance_metrics['balance_ratio'] * 0.3
                
                result = {
                    'labels': labels,
                    'clusterer': clusterer,
                    'params': {
                        'algorithm': 'hdbscan',
                        'min_cluster_size': min_cluster_size,
                        'min_samples': min_samples
                    },
                    'metrics': {
                        **balance_metrics,
                        'silhouette': silhouette,
                        'combined_score': combined_score,
                        'fit_time': fit_time
                    }
                }
                
                results.append(result)
                
                silhouette_str = f"{silhouette:.3f}" if silhouette is not None else "N/A"
                logger.info(f"  min_size={min_cluster_size}, min_samples={min_samples}: "
                          f"{balance_metrics['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, "
                          f"—à—É–º={balance_metrics['noise_ratio']:.1%}, "
                          f"silhouette={silhouette_str}")
                
                if combined_score > best_score:
                    best_score = combined_score
                    best_result = result
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ HDBSCAN: {e}")
    
    if best_result is None:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å HDBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
    
    return {'hdbscan_best': best_result, 'hdbscan_all_results': results}

def perform_clustering(X: np.ndarray, params: Dict) -> Tuple[np.ndarray, Any, Dict]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
    
    Returns:
        Tuple[labels, clusterer, results_dict]
    """
    logger.info("üéØ –ó–∞–ø—É—Å–∫ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    algorithm = params.get('algorithm', 'gmm').lower()
    
    if algorithm == 'gmm':
        results = run_gmm_clustering(X, params)
        best_result = results['gmm_best']
    elif algorithm == 'gmm_auto':
        results = run_gmm_clustering_auto(X, params)
        best_result = results['gmm_auto_best']
    elif algorithm == 'kmeans':
        results = run_kmeans_clustering(X, params)
        best_result = results['kmeans_best']
    elif algorithm == 'hdbscan':
        results = run_hdbscan_clustering(X, params)
        best_result = results['hdbscan_best']
    else:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤...")
        
        all_results = {}
        best_overall = None
        best_overall_score = -1
        
        # GMM Auto (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π)
        try:
            gmm_auto_results = run_gmm_clustering_auto(X, params)
            all_results.update(gmm_auto_results)
            if gmm_auto_results['gmm_auto_best']['metrics']['combined_score'] > best_overall_score:
                best_overall_score = gmm_auto_results['gmm_auto_best']['metrics']['combined_score']
                best_overall = gmm_auto_results['gmm_auto_best']
        except Exception as e:
            logger.error(f"GMM Auto failed: {e}")
        
        # GMM (fallback)
        try:
            gmm_results = run_gmm_clustering(X, params)
            all_results.update(gmm_results)
            if gmm_results['gmm_best']['metrics']['combined_score'] > best_overall_score:
                best_overall_score = gmm_results['gmm_best']['metrics']['combined_score']
                best_overall = gmm_results['gmm_best']
        except Exception as e:
            logger.error(f"GMM failed: {e}")
        
        # K-Means
        try:
            kmeans_results = run_kmeans_clustering(X, params)
            all_results.update(kmeans_results)
            if kmeans_results['kmeans_best']['metrics']['combined_score'] > best_overall_score:
                best_overall_score = kmeans_results['kmeans_best']['metrics']['combined_score']
                best_overall = kmeans_results['kmeans_best']
        except Exception as e:
            logger.error(f"K-Means failed: {e}")
        
        # HDBSCAN
        try:
            hdbscan_results = run_hdbscan_clustering(X, params)
            all_results.update(hdbscan_results)
            if hdbscan_results['hdbscan_best']['metrics']['combined_score'] > best_overall_score:
                best_overall_score = hdbscan_results['hdbscan_best']['metrics']['combined_score']
                best_overall = hdbscan_results['hdbscan_best']
        except Exception as e:
            logger.error(f"HDBSCAN failed: {e}")
        
        if best_overall is None:
            raise ValueError("–í—Å–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π")
        
        results = all_results
        best_result = best_overall
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    metrics = best_result['metrics']
    silhouette_str = f"{metrics['silhouette']:.3f}" if metrics['silhouette'] is not None else "N/A"
    logger.info(f"üèÜ –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
    logger.info(f"   –ê–ª–≥–æ—Ä–∏—Ç–º: {best_result['params']['algorithm'].upper()}")
    logger.info(f"   –ö–ª–∞—Å—Ç–µ—Ä—ã: {metrics['n_clusters']}")
    logger.info(f"   –†–∞–∑–º–µ—Ä—ã: {metrics.get('cluster_sizes', 'N/A')}")
    logger.info(f"   –ë–∞–ª–∞–Ω—Å: {metrics['balance_ratio']:.3f}")
    logger.info(f"   –°–∞–º—ã–π –±–æ–ª—å—à–æ–π: {metrics['largest_cluster_pct']:.1f}%")
    logger.info(f"   Silhouette: {silhouette_str}")
    if 'bic' in metrics:
        logger.info(f"   BIC: {metrics['bic']:.1f}")
    if 'optimal_n_components' in metrics:
        logger.info(f"   –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {metrics['optimal_n_components']}")
    logger.info(f"   –í—Ä–µ–º—è: {metrics['fit_time']:.1f}—Å")
    
    return best_result['labels'], best_result['clusterer'], results 